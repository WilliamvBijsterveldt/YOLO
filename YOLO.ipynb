{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AR challenge 2/3: Custom Object Detection network\n",
    "\n",
    "### members: Jens Boeijen, Daan Hovens en William van Bijsterveldt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Objective\n",
    "\n",
    "This notebook contains code that trains and uses the YOLOv11 model to process data from a live video. In the video there will be custom objects that has to be bound in boxes and the location in the world be shown. \n",
    "\n",
    "### Overview\n",
    "\n",
    "As mentioned before we will be using the YOLOv11 model to process the data. To get the data we will be using a Intel Realsense d435 RGB-D camera to record and transmit the video to our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testfase\n",
    "\n",
    "1. Python programma video omzetten naar foto's.\n",
    "2. Roboflow foto's objecteren omcirkelen.\n",
    "3. Roboflow test uitvoeren.\n",
    "4. Foto naderhand maken om te kijken of de test goed gelukt was.\n",
    "5. Blijven herhalen tot de juiste percentage van het detecteren van de objecten er is.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
